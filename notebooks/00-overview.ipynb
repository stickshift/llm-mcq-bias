{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34045730-6901-497f-9164-4946a659b2da",
   "metadata": {},
   "source": [
    "# Exploring Order Dependency in LLMs\n",
    "\n",
    "While LLMs have demonstrated remarkable capabilities in understanding and generating text, they also exhibit a number of unexpected behavioral patterns. Hallucinations are one well known example, but there are others that are less obvious and more subtle. Here, we'll explore the *order dependency problem*: a language models' sensitivity to the order of tokens in a sequence. Like hallucinations, order dependency is a significant obstacle to user acceptance and broader adoption of AI solutions. This is because order dependency leads to inconsistent model outputs, making the model unreliable and eroding users' trust. Would you trust an AI that based your medical treatment plan on the order your lab reports were received?\n",
    "\n",
    "One specific area where order dependency has been thoroughly studied is in answering multiple choice questions (MCQs). Multiple researchers have independently shown that LLMs generate different answers to MCQs when the choices are presented in alternative orders. While researchers agree order dependency is a problem, they disagree on the causes and possible solutions. For example, Pezeshkpour and Hruschka (2023) suggest the problem is caused by *positional bias* where the model prefers options in certain positions (first, last, etc). In contrast, Zheng et al. (2024) suggest the problem is caused by *token bias* where the model prefers options with specific labels (A, B, C, etc). Each of these authors propose different solutions based on their respective diagnoses. McIlroy-Young et al. (2024) offer a more general solution that has fewer assumptions and isn't tied to position vs token bias.\n",
    "\n",
    "Over the rest of this post, we'll explore different aspects of the order dependency problem. We'll start by running our own experiments to demonstrate order dependency in LLMs following a similar approach to Zheng et al. (2024). Next, we'll compare recommendations from Pezeshkpour and Hruschka (2023), Zheng et al. (2024), and McIlroy-Young et al. (2024). Finally, we'll briefly discuss a handful of key take aways from the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6015a8b0-b0a8-46d8-83e0-c596e76bbde2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a0eb5eb-6768-4290-8c95-4ec7c7ac4b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import llm_mcq_bias as lmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6069083-5368-45e2-9b30-d1532767458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to project root\n",
    "os.chdir(\"..\")\n",
    "\n",
    "# Configure logger\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150c9b32-4a62-4853-83e6-33d3aa36138b",
   "metadata": {},
   "source": [
    "# Measuring Order Dependency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecebbb81-9ccc-488d-a206-52383635f729",
   "metadata": {},
   "source": [
    "Our first goal is to demonstrate order dependency in an MCQ setting for ourselves. We'll follow a similar process to Zheng et al. (2024) scaled down to fit into a more limited budget."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da697a8f-f0fd-4160-8aa3-7936148f203b",
   "metadata": {},
   "source": [
    "## MMLU Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bff713-6a93-4c06-a08d-794decfdfb25",
   "metadata": {},
   "source": [
    "We'll start by downloading the Massive Multitask Language Understanding (MMLU) benchmark dataset from <https://github.com/hendrycks/test>. MMLU contains 14,042 MCQs from 57 categories. Each question has 4 options A, B, C, and D and one correct answer. In addition, each category has 5 example questions designed for few-shot experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df900f6b-8203-4f9f-8c53-fa0354cf0a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded datasets .build/datasets/mmlu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!make datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34666d8b-9c84-4c0a-abe6-fb83304e6568",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = Path(\".build\") / \"datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dd446f2-12c3-453f-8fbb-1afead3f851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example questions\n",
    "examples = lmb.datasets.mmlu.load_dataset(datasets_path, segment=\"dev\")\n",
    "\n",
    "# Load test questions\n",
    "questions = lmb.datasets.mmlu.load_dataset(datasets_path, segment=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a89a085-aaca-484e-9e97-34775b664e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8132</th>\n",
       "      <td>Which of these is not a style of shoe?</td>\n",
       "      <td>gingham</td>\n",
       "      <td>brogan</td>\n",
       "      <td>espadrille</td>\n",
       "      <td>docksider</td>\n",
       "      <td>A</td>\n",
       "      <td>miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5580</th>\n",
       "      <td>A reading specialist in a large public school ...</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>No, because while this design may point out an...</td>\n",
       "      <td>No, because without blinding, there is a stron...</td>\n",
       "      <td>No, because grade level is a lurking variable ...</td>\n",
       "      <td>D</td>\n",
       "      <td>high school statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>In fluorescence spectroscopy, the quantum yiel...</td>\n",
       "      <td>rate of fluorescence emission</td>\n",
       "      <td>number of photons emitted</td>\n",
       "      <td>number of photons emitted, divided by the numb...</td>\n",
       "      <td>number of excitation photons impinging on the ...</td>\n",
       "      <td>C</td>\n",
       "      <td>college chemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "8132             Which of these is not a style of shoe?   \n",
       "5580  A reading specialist in a large public school ...   \n",
       "951   In fluorescence spectroscopy, the quantum yiel...   \n",
       "\n",
       "                                  A  \\\n",
       "8132                        gingham   \n",
       "5580                           Yes.   \n",
       "951   rate of fluorescence emission   \n",
       "\n",
       "                                                      B  \\\n",
       "8132                                             brogan   \n",
       "5580  No, because while this design may point out an...   \n",
       "951                           number of photons emitted   \n",
       "\n",
       "                                                      C  \\\n",
       "8132                                         espadrille   \n",
       "5580  No, because without blinding, there is a stron...   \n",
       "951   number of photons emitted, divided by the numb...   \n",
       "\n",
       "                                                      D answer  \\\n",
       "8132                                          docksider      A   \n",
       "5580  No, because grade level is a lurking variable ...      D   \n",
       "951   number of excitation photons impinging on the ...      C   \n",
       "\n",
       "                    category  \n",
       "8132           miscellaneous  \n",
       "5580  high school statistics  \n",
       "951        college chemistry  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display random sample of questions\n",
    "questions.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7ef4bf-bba9-4398-9e88-da8f8977f741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd1e64-c5a5-4882-aec3-309c0f55b3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73303535-5553-4b35-86a6-9a397a5e86ac",
   "metadata": {},
   "source": [
    "# Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e14992f-30ca-443f-bb54-2987c2dcc224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687df09b-41f7-4159-846c-11ecb7dac4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3cb0cd-82b5-48af-8a47-558e8a3b9445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5422f5-ac5f-47c9-a3e9-260c1fce2be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae053dc8-877c-4f61-8878-85cc8e1258e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284089a5-d6ce-402b-81a4-4e148937c51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b781f114-8a8a-48bc-ab78-43a28c4ff60a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb3c11c-19d3-4839-b5a1-30f5e9f2f22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f4f8db-c65b-4080-a99c-6f32c9103d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38664f-e02c-4a0f-b0fe-fd9da7173792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7afb94-5916-40fe-8c4c-414570fd1ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
