{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf3002f-3004-4fc6-90f1-0af07682b26e",
   "metadata": {},
   "source": [
    "# Demonstrate Positional Bias\n",
    "\n",
    "Our goal here is to quantify positional bias inherrent in our LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5dde05-1cdb-4b1b-9624-e848d0211089",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1c16667-139d-4211-8ace-4c48419b614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from time import perf_counter_ns as timer\n",
    "\n",
    "from pandas import DataFrame\n",
    "import rich\n",
    "from rich.table import Table\n",
    "from tqdm import tqdm\n",
    "\n",
    "import llm_mcq_bias as lmb\n",
    "from llm_mcq_bias.datasets.mmlu import Evaluation, OPTIONS\n",
    "from llm_mcq_bias.models import gpt_4o_mini as generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9972849e-862d-44be-bdff-6299e8e152fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(rows, title: str | None = None):\n",
    "    table = Table(*[k for k in rows[0]], title=title, box=rich.box.SIMPLE)\n",
    "    for row in rows:\n",
    "        table.add_row(*[str(v) for v in row.values()])\n",
    "    rich.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52d9ede7-ba69-4129-8c04-e1c5cda116f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = Path(\"../\")\n",
    "datasets_path = project_path / \".build\" / \"datasets\"\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd3a0af-90a2-40cc-bdc2-7e52ff1da1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Boston'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warm up model\n",
    "generator(\n",
    "    prompt=\"What is the capital of Massachusetts? Answer in one word.\",\n",
    "    options={\"max_tokens\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac59e38-4538-416b-bc05-a441ff8a36bc",
   "metadata": {},
   "source": [
    "# Demonstrate Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d74b570-6ba6-4056-bef7-ef4e44515768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations\n",
    "n_epochs = 3\n",
    "\n",
    "# Number of questions to sample\n",
    "n_questions = 240\n",
    "\n",
    "# Number of workers\n",
    "n_jobs = 3\n",
    "\n",
    "llm_options = {\n",
    "    # Limit output tokens to avoid waiting for invalid responses\n",
    "    \"max_tokens\": 10,\n",
    "    # Disable token sampling\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef74a8b5-342f-4fe3-820d-a58ce0f06569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example questions\n",
    "examples = lmb.datasets.mmlu.load_dataset(datasets_path, segment=\"dev\")\n",
    "\n",
    "# Debias example answer distribution\n",
    "examples = lmb.datasets.mmlu.normalize_example_answers(examples)\n",
    "\n",
    "# Load test questions\n",
    "questions = lmb.datasets.mmlu.load_dataset(datasets_path, segment=\"test\")\n",
    "\n",
    "# Initialize thread pool\n",
    "executor = ThreadPoolExecutor(max_workers=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2bd801b-7838-4763-ad8e-564fc6655a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mcq(generator, generator_options, mcq):\n",
    "    # Generate prompt\n",
    "    prompt = lmb.datasets.mmlu.generate_prompt(examples, mcq)\n",
    "\n",
    "    # Generate answer\n",
    "    response = generator(prompt=prompt, options=generator_options)\n",
    "\n",
    "    # Evaluate response\n",
    "    evaluation = lmb.datasets.mmlu.evaluate_response(mcq, response)\n",
    "\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "def benchmark(\n",
    "    description: str,\n",
    "    *,\n",
    "    examples: DataFrame,\n",
    "    questions: DataFrame,\n",
    "    generator,\n",
    "    generator_options: dict,\n",
    "):\n",
    "    n = len(questions)\n",
    "\n",
    "    start_time = timer()\n",
    "\n",
    "    # Answer and evaluate each question\n",
    "    futures = [\n",
    "        executor.submit(process_mcq, generator, generator_options, mcq)\n",
    "        for _, mcq in questions.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Collect results\n",
    "    correct, errors = 0, 0\n",
    "    for future in tqdm(as_completed(futures), total=n, desc=description):\n",
    "        evaluation = future.result()\n",
    "        if evaluation is Evaluation.CORRECT:\n",
    "            correct += 1\n",
    "        elif evaluation is Evaluation.ERROR:\n",
    "            errors += 1\n",
    "\n",
    "    duration = timer() - start_time\n",
    "\n",
    "    # Derive metrics\n",
    "    metrics = {\n",
    "        \"n\": n,\n",
    "        \"correct\": correct,\n",
    "        \"errors\": errors,\n",
    "        \"accuracy\": correct / (n - errors),\n",
    "        \"error_rate\": errors / n,\n",
    "        \"rps\": 1000000000 * n / duration,\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725062b-af28-465e-9e63-ed811d778d04",
   "metadata": {},
   "source": [
    "### Verify Stable Benchmark Results\n",
    "\n",
    "Let's make sure our benchmark process produces consistent results when run against the same inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc163e0-0718-4d08-b107-08424c406df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='answer'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample questions\n",
    "selected_questions = questions.sample(n=16)\n",
    "\n",
    "# Debias answer distribution\n",
    "selected_questions = lmb.datasets.mmlu.normalize_question_answers(selected_questions)\n",
    "\n",
    "# Plot answer distribution\n",
    "selected_questions.answer.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fafbe10b-2249-435a-950c-d716b4ab8fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a robot that only outputs JSON. You reply in JSON format with the field 'answer'. For example, the following are multiple choice questions about high school biology.\n",
      "\n",
      "Example Question: Which of the following is not known to be involved in the control of cell division?\n",
      "\n",
      "A) Cyclins\n",
      "B) Fibroblast cells\n",
      "C) Checkpoints\n",
      "D) Protein kinases\n",
      "\n",
      "Example Answer: {\"answer\": \"B\"}\n",
      "\n",
      "Example Question: Which of the following is not a way to form recombinant DNA?\n",
      "\n",
      "A) Specialized transduction\n",
      "B) Conjugation\n",
      "C) Translation\n",
      "D) Transformation\n",
      "\n",
      "Example Answer: {\"answer\": \"C\"}\n",
      "\n",
      "Example Question: In animal cells, which of the following represents the most likely pathway that a secretory protein takes as it is synthesized in a cell?\n",
      "\n",
      "A) Plasma membrane–Golgi apparatus–ribosome–secretory vesicle–rough ER\n",
      "B) Ribosome–Golgi apparatus–rough ER–secretory vesicle–plasma membrane\n",
      "C) Plasma membrane–Golgi apparatus–ribosome–secretory vesicle–rough ER\n",
      "D) Ribosome–rough ER–Golgi apparatus–secretory vesicle–plasma membrane\n",
      "\n",
      "Example Answer: {\"answer\": \"D\"}\n",
      "\n",
      "Example Question: A mutation in a bacterial enzyme changed a previously polar amino acid into a nonpolar amino acid. This amino acid was located at a site distant from the enzyme’s active site. How might this mutation alter the enzyme’s substrate specificity?\n",
      "\n",
      "A) By changing the shape of the protein\n",
      "B) By changing the enzyme’s location in the cell\n",
      "C) By changing the enzyme’s pH optimum\n",
      "D) An amino acid change away from the active site cannot alter the enzyme’s substrate specificity.\n",
      "\n",
      "Example Answer: {\"answer\": \"A\"}\n",
      "\n",
      "Given the examples above, your task is to answer the following question.\n",
      "\n",
      "Question: Monkeys of South and Central America have prehensile tails, meaning that their tails can be used to grasp objects. The tails of African and Asian monkeys are not prehensile. Which discipline is most likely to provide an evolutionary explanation for how this difference in tails came about?\n",
      "\n",
      "A) Aerodynamics\n",
      "B) Biochemistry\n",
      "C) Physiology\n",
      "D) Biogeography\n",
      "\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "# Print example prompt\n",
    "print(lmb.datasets.mmlu.generate_prompt(examples, selected_questions.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0c1ff00-a43e-41d1-9c89-6e6642f09620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  6.61it/s]\n",
      "epoch 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.81it/s]\n",
      "epoch 2: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  6.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                     \n",
       " <span style=\"font-weight: bold\"> n  </span> <span style=\"font-weight: bold\"> correct </span> <span style=\"font-weight: bold\"> errors </span> <span style=\"font-weight: bold\"> accuracy </span> <span style=\"font-weight: bold\"> error_rate </span> <span style=\"font-weight: bold\"> rps               </span> \n",
       " ─────────────────────────────────────────────────────────────────── \n",
       "  16   13        0        0.8125     0.0          6.574058982499922  \n",
       "  16   13        0        0.8125     0.0          5.787201229614747  \n",
       "  16   13        0        0.8125     0.0          6.41856819634496   \n",
       "                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                                                     \n",
       " \u001b[1m \u001b[0m\u001b[1mn \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mcorrect\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merrors\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1maccuracy\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merror_rate\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mrps              \u001b[0m\u001b[1m \u001b[0m \n",
       " ─────────────────────────────────────────────────────────────────── \n",
       "  16   13        0        0.8125     0.0          6.574058982499922  \n",
       "  16   13        0        0.8125     0.0          5.787201229614747  \n",
       "  16   13        0        0.8125     0.0          6.41856819634496   \n",
       "                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.92 s, sys: 52.5 ms, total: 1.97 s\n",
      "Wall time: 7.73 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rows = []\n",
    "for i in range(n_epochs):\n",
    "    # Run benchmark\n",
    "    metrics = benchmark(\n",
    "        f\"epoch {i}\",\n",
    "        examples=examples,\n",
    "        questions=selected_questions,\n",
    "        generator=generator,\n",
    "        generator_options=llm_options,\n",
    "    )\n",
    "\n",
    "    rows.append(metrics)\n",
    "\n",
    "print_table(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c39e34-9333-4798-b059-b55748fbcade",
   "metadata": {},
   "source": [
    "## Estimate Positional Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af877f4d-2cc3-40b3-8a92-3ad28e5e0a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uniform: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:40<00:00,  5.98it/s]\n",
      "D: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:40<00:00,  5.91it/s]\n",
      "B: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:38<00:00,  6.31it/s]\n",
      "A: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:39<00:00,  6.06it/s]\n",
      "C: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:37<00:00,  6.42it/s]\n",
      "uniform: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:38<00:00,  6.16it/s]\n",
      "D: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:37<00:00,  6.48it/s]\n",
      "B: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:42<00:00,  5.60it/s]\n",
      "A: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:50<00:00,  4.77it/s]\n",
      "C: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:49<00:00,  4.81it/s]\n",
      "uniform: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:46<00:00,  5.17it/s]\n",
      "D: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:45<00:00,  5.25it/s]\n",
      "B: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:46<00:00,  5.21it/s]\n",
      "A: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:47<00:00,  5.00it/s]\n",
      "C: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [01:46<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 9s, sys: 3.14 s, total: 2min 12s\n",
      "Wall time: 11min 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Repeat over multiple iterations\n",
    "rows = []\n",
    "for _ in range(n_epochs):\n",
    "    # Sample questions\n",
    "    selected_questions = questions.sample(n=n_questions)\n",
    "\n",
    "    # Debias answer distribution\n",
    "    selected_questions = lmb.datasets.mmlu.normalize_question_answers(\n",
    "        selected_questions\n",
    "    )\n",
    "\n",
    "    # Initialize metrics\n",
    "    metrics = {}\n",
    "\n",
    "    # Record performance w/ original data\n",
    "    metrics[\"uniform\"] = benchmark(\n",
    "        \"uniform\",\n",
    "        examples=examples,\n",
    "        questions=selected_questions,\n",
    "        generator=generator,\n",
    "        generator_options=llm_options,\n",
    "    )\n",
    "\n",
    "    # Record performance w/ answers shifted to each position\n",
    "    for option in OPTIONS:\n",
    "        # Swap answers to selected option\n",
    "        q = lmb.datasets.mmlu.swap_options(selected_questions, option)\n",
    "\n",
    "        metrics[option] = benchmark(\n",
    "            option,\n",
    "            examples=examples,\n",
    "            questions=q,\n",
    "            generator=generator,\n",
    "            generator_options=llm_options,\n",
    "        )\n",
    "\n",
    "    rows.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b84788bf-d50f-4e45-9755-8ac2bc3ce45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                         uniform                                          </span>\n",
       "                                                                                          \n",
       " <span style=\"font-weight: bold\"> n   </span> <span style=\"font-weight: bold\"> correct </span> <span style=\"font-weight: bold\"> errors </span> <span style=\"font-weight: bold\"> accuracy           </span> <span style=\"font-weight: bold\"> error_rate           </span> <span style=\"font-weight: bold\"> rps               </span> \n",
       " ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  240   188       1        0.7866108786610879   0.004166666666666667   5.980479845653368  \n",
       "  240   192       1        0.803347280334728    0.004166666666666667   6.158617979124051  \n",
       "  240   186       0        0.775                0.0                    5.16404290959638   \n",
       "                                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                         uniform                                          \u001b[0m\n",
       "                                                                                          \n",
       " \u001b[1m \u001b[0m\u001b[1mn  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mcorrect\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merrors\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1maccuracy          \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merror_rate          \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mrps              \u001b[0m\u001b[1m \u001b[0m \n",
       " ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  240   188       1        0.7866108786610879   0.004166666666666667   5.980479845653368  \n",
       "  240   192       1        0.803347280334728    0.004166666666666667   6.158617979124051  \n",
       "  240   186       0        0.775                0.0                    5.16404290959638   \n",
       "                                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                             D                                             </span>\n",
       "                                                                                           \n",
       " <span style=\"font-weight: bold\"> n   </span> <span style=\"font-weight: bold\"> correct </span> <span style=\"font-weight: bold\"> errors </span> <span style=\"font-weight: bold\"> accuracy           </span> <span style=\"font-weight: bold\"> error_rate           </span> <span style=\"font-weight: bold\"> rps                </span> \n",
       " ───────────────────────────────────────────────────────────────────────────────────────── \n",
       "  240   167       0        0.6958333333333333   0.0                    5.9047667839035025  \n",
       "  240   175       0        0.7291666666666666   0.0                    6.480192588926071   \n",
       "  240   170       1        0.7112970711297071   0.004166666666666667   5.243543707366408   \n",
       "                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                             D                                             \u001b[0m\n",
       "                                                                                           \n",
       " \u001b[1m \u001b[0m\u001b[1mn  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mcorrect\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merrors\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1maccuracy          \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merror_rate          \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mrps               \u001b[0m\u001b[1m \u001b[0m \n",
       " ───────────────────────────────────────────────────────────────────────────────────────── \n",
       "  240   167       0        0.6958333333333333   0.0                    5.9047667839035025  \n",
       "  240   175       0        0.7291666666666666   0.0                    6.480192588926071   \n",
       "  240   170       1        0.7112970711297071   0.004166666666666667   5.243543707366408   \n",
       "                                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                        B                                        </span>\n",
       "                                                                                 \n",
       " <span style=\"font-weight: bold\"> n   </span> <span style=\"font-weight: bold\"> correct </span> <span style=\"font-weight: bold\"> errors </span> <span style=\"font-weight: bold\"> accuracy           </span> <span style=\"font-weight: bold\"> error_rate </span> <span style=\"font-weight: bold\"> rps                </span> \n",
       " ─────────────────────────────────────────────────────────────────────────────── \n",
       "  240   185       0        0.7708333333333334   0.0          6.309858661682298   \n",
       "  240   191       0        0.7958333333333333   0.0          5.6029896973489155  \n",
       "  240   193       0        0.8041666666666667   0.0          5.208531106956295   \n",
       "                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                        B                                        \u001b[0m\n",
       "                                                                                 \n",
       " \u001b[1m \u001b[0m\u001b[1mn  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mcorrect\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merrors\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1maccuracy          \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merror_rate\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mrps               \u001b[0m\u001b[1m \u001b[0m \n",
       " ─────────────────────────────────────────────────────────────────────────────── \n",
       "  240   185       0        0.7708333333333334   0.0          6.309858661682298   \n",
       "  240   191       0        0.7958333333333333   0.0          5.6029896973489155  \n",
       "  240   193       0        0.8041666666666667   0.0          5.208531106956295   \n",
       "                                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                            A                                             </span>\n",
       "                                                                                          \n",
       " <span style=\"font-weight: bold\"> n   </span> <span style=\"font-weight: bold\"> correct </span> <span style=\"font-weight: bold\"> errors </span> <span style=\"font-weight: bold\"> accuracy           </span> <span style=\"font-weight: bold\"> error_rate           </span> <span style=\"font-weight: bold\"> rps               </span> \n",
       " ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  240   186       0        0.775                0.0                    6.05992985491663   \n",
       "  240   197       1        0.8242677824267782   0.004166666666666667   4.765114617424156  \n",
       "  240   188       0        0.7833333333333333   0.0                    5.001953064260789  \n",
       "                                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                            A                                             \u001b[0m\n",
       "                                                                                          \n",
       " \u001b[1m \u001b[0m\u001b[1mn  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mcorrect\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merrors\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1maccuracy          \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merror_rate          \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mrps              \u001b[0m\u001b[1m \u001b[0m \n",
       " ──────────────────────────────────────────────────────────────────────────────────────── \n",
       "  240   186       0        0.775                0.0                    6.05992985491663   \n",
       "  240   197       1        0.8242677824267782   0.004166666666666667   4.765114617424156  \n",
       "  240   188       0        0.7833333333333333   0.0                    5.001953064260789  \n",
       "                                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                             C                                             </span>\n",
       "                                                                                           \n",
       " <span style=\"font-weight: bold\"> n   </span> <span style=\"font-weight: bold\"> correct </span> <span style=\"font-weight: bold\"> errors </span> <span style=\"font-weight: bold\"> accuracy           </span> <span style=\"font-weight: bold\"> error_rate           </span> <span style=\"font-weight: bold\"> rps                </span> \n",
       " ───────────────────────────────────────────────────────────────────────────────────────── \n",
       "  240   182       0        0.7583333333333333   0.0                    6.4130559832553224  \n",
       "  240   185       0        0.7708333333333334   0.0                    4.806972580930116   \n",
       "  240   189       1        0.7907949790794979   0.004166666666666667   2.245580981522416   \n",
       "                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                             C                                             \u001b[0m\n",
       "                                                                                           \n",
       " \u001b[1m \u001b[0m\u001b[1mn  \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mcorrect\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merrors\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1maccuracy          \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merror_rate          \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mrps               \u001b[0m\u001b[1m \u001b[0m \n",
       " ───────────────────────────────────────────────────────────────────────────────────────── \n",
       "  240   182       0        0.7583333333333333   0.0                    6.4130559832553224  \n",
       "  240   185       0        0.7708333333333334   0.0                    4.806972580930116   \n",
       "  240   189       1        0.7907949790794979   0.004166666666666667   2.245580981522416   \n",
       "                                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keys = [k for k in rows[0]]\n",
    "\n",
    "for k in keys:\n",
    "    print_table([row[k] for row in rows], title=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7cf71dd-01e1-42e7-ab66-798960c4b2e4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                           \n",
       " <span style=\"font-weight: bold\"> uniform </span> <span style=\"font-weight: bold\"> A     </span> <span style=\"font-weight: bold\"> B     </span> <span style=\"font-weight: bold\"> C     </span> <span style=\"font-weight: bold\"> D     </span> \n",
       " ───────────────────────────────────────── \n",
       "  0.79      <span style=\"color: #000000; text-decoration-color: #000000\">-0.01</span>   <span style=\"color: #000000; text-decoration-color: #000000\">-0.02</span>   <span style=\"color: #000000; text-decoration-color: #000000\">-0.03</span>   <span style=\"color: #800000; text-decoration-color: #800000\">-0.09</span>  \n",
       "  0.80      <span style=\"color: #000000; text-decoration-color: #000000\">0.02</span>    <span style=\"color: #000000; text-decoration-color: #000000\">-0.01</span>   <span style=\"color: #000000; text-decoration-color: #000000\">-0.03</span>   <span style=\"color: #800000; text-decoration-color: #800000\">-0.07</span>  \n",
       "  0.78      <span style=\"color: #000000; text-decoration-color: #000000\">0.01</span>    <span style=\"color: #000000; text-decoration-color: #000000\">0.03</span>    <span style=\"color: #000000; text-decoration-color: #000000\">0.02</span>    <span style=\"color: #800000; text-decoration-color: #800000\">-0.06</span>  \n",
       "                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                           \n",
       " \u001b[1m \u001b[0m\u001b[1muniform\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mA    \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mB    \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mC    \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mD    \u001b[0m\u001b[1m \u001b[0m \n",
       " ───────────────────────────────────────── \n",
       "  0.79      \u001b[30m-0.01\u001b[0m   \u001b[30m-0.02\u001b[0m   \u001b[30m-0.03\u001b[0m   \u001b[31m-0.09\u001b[0m  \n",
       "  0.80      \u001b[30m0.02\u001b[0m    \u001b[30m-0.01\u001b[0m   \u001b[30m-0.03\u001b[0m   \u001b[31m-0.07\u001b[0m  \n",
       "  0.78      \u001b[30m0.01\u001b[0m    \u001b[30m0.03\u001b[0m    \u001b[30m0.02\u001b[0m    \u001b[31m-0.06\u001b[0m  \n",
       "                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = Table(\"uniform\", \"A\", \"B\", \"C\", \"D\", box=rich.box.SIMPLE)\n",
    "for row in rows:\n",
    "    baseline = row[\"uniform\"][\"accuracy\"]\n",
    "    offsets = {k: row[k][\"accuracy\"] - baseline for k in OPTIONS}\n",
    "    colors = {option: \"black\" for option in OPTIONS}\n",
    "    colors |= {option: \"red\" for option in OPTIONS if offsets[option] <= -0.05}\n",
    "    colors |= {option: \"green\" for option in OPTIONS if offsets[option] >= 0.05}\n",
    "    table.add_row(\n",
    "        f\"{baseline:0.2f}\",\n",
    "        f\"[{colors['A']}]{offsets['A']:0.2f}[/{colors['A']}]\",\n",
    "        f\"[{colors['B']}]{offsets['B']:0.2f}[/{colors['B']}]\",\n",
    "        f\"[{colors['C']}]{offsets['C']:0.2f}[/{colors['C']}]\",\n",
    "        f\"[{colors['D']}]{offsets['D']:0.2f}[/{colors['D']}]\",\n",
    "    )\n",
    "\n",
    "rich.print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940a7c2e-c8f3-465b-b68e-8f78f88e9171",
   "metadata": {},
   "source": [
    "# Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "000a8cfc-cc6e-410f-8bec-264b152f5e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1928"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path(\"results/demonstrate-bias-gpt-4o-mini-run1.json\")\n",
    "path.write_text(json.dumps(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df4207d-7cf3-4eaf-9291-1fbfcc5729fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e3f48-eb24-4c3a-a4bd-38341b4f7dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
