{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf3002f-3004-4fc6-90f1-0af07682b26e",
   "metadata": {},
   "source": [
    "# Demonstrate Positional Bias\n",
    "\n",
    "Our goal here is to quantify positional bias inherrent in our LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5dde05-1cdb-4b1b-9624-e848d0211089",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c16667-139d-4211-8ace-4c48419b614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from time import perf_counter_ns as timer\n",
    "\n",
    "from pandas import DataFrame, Series\n",
    "import rich\n",
    "from rich.table import Table\n",
    "from tqdm import tqdm\n",
    "\n",
    "import llm_mcq_bias as lmb\n",
    "from llm_mcq_bias.datasets.mmlu import Evaluation, OPTIONS\n",
    "from llm_mcq_bias.models import llama_323b as generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9972849e-862d-44be-bdff-6299e8e152fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def print_table(rows):\n",
    "    table = Table(*[k for k in rows[0]], box=rich.box.SIMPLE)\n",
    "    for row in rows:\n",
    "        table.add_row(*[str(v) for v in row.values()])\n",
    "    rich.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52d9ede7-ba69-4129-8c04-e1c5cda116f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = Path(\"../\")\n",
    "datasets_path = project_path / \".build\" / \"datasets\"\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd3a0af-90a2-40cc-bdc2-7e52ff1da1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Boston'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warm up model\n",
    "generator(prompt=\"What is the capital of Massachusetts? Answer in one word.\", options={\"num_predict\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac59e38-4538-416b-bc05-a441ff8a36bc",
   "metadata": {},
   "source": [
    "# Demonstrate Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d74b570-6ba6-4056-bef7-ef4e44515768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations\n",
    "n_epochs = 3\n",
    "\n",
    "# Number of questions to sample\n",
    "n_questions = 240\n",
    "\n",
    "llm_options = {\n",
    "    # Limit output tokens to avoid waiting for invalid responses\n",
    "    \"num_predict\": 10,\n",
    "\n",
    "    # Disable token sampling\n",
    "    \"top_k\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef74a8b5-342f-4fe3-820d-a58ce0f06569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example questions\n",
    "examples = lmb.datasets.mmlu.load_dataset(datasets_path, segment=\"dev\")\n",
    "\n",
    "# Debias example answer distribution\n",
    "examples = lmb.datasets.mmlu.normalize_example_answers(examples)\n",
    "\n",
    "# Load test questions\n",
    "questions = lmb.datasets.mmlu.load_dataset(datasets_path, segment=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2bd801b-7838-4763-ad8e-564fc6655a64",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def benchmark(description: str, *, examples: DataFrame, questions: DataFrame, generator_options: dict):\n",
    "\n",
    "    n = len(questions)\n",
    "    \n",
    "    start_time = timer()\n",
    "    \n",
    "    # Answer and evaluate each question\n",
    "    correct, errors = 0, 0\n",
    "    for _, mcq in tqdm(questions.iterrows(), total=n, desc=description):\n",
    "    \n",
    "        # Generate prompt\n",
    "        prompt = lmb.datasets.mmlu.generate_prompt(examples, mcq)\n",
    "        \n",
    "        # Generate answer\n",
    "        response = lmb.models.llama_323b(prompt=prompt, options=generator_options)\n",
    "        \n",
    "        # Evaluate answer\n",
    "        evaluation = lmb.datasets.mmlu.evaluate_response(mcq, response)\n",
    "        if evaluation is Evaluation.CORRECT:\n",
    "            correct += 1\n",
    "        elif evaluation is Evaluation.ERROR:\n",
    "            errors += 1\n",
    "\n",
    "    duration = timer() - start_time\n",
    "    \n",
    "    # Derive metrics\n",
    "    metrics = {\n",
    "        \"n\": n,\n",
    "        \"correct\": correct,\n",
    "        \"errors\": errors,\n",
    "        \"accuracy\": correct / (n - errors),\n",
    "        \"error_rate\": errors / n,\n",
    "        \"rps\": 1000000000 * n / duration,\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725062b-af28-465e-9e63-ed811d778d04",
   "metadata": {},
   "source": [
    "### Verify Stable Benchmark Results\n",
    "\n",
    "Let's make sure our benchmark process produces consistent results when run against the same inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc163e0-0718-4d08-b107-08424c406df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='answer'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample questions\n",
    "selected_questions = questions.sample(n=16)\n",
    "\n",
    "# Debias answer distribution\n",
    "selected_questions = lmb.datasets.mmlu.normalize_question_answers(selected_questions)\n",
    "\n",
    "# Plot answer distribution\n",
    "selected_questions.answer.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fafbe10b-2249-435a-950c-d716b4ab8fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a robot that only outputs JSON. You reply in JSON format with the field 'answer'. For example, the following are multiple choice questions about professional law.\n",
      "\n",
      "Example Question: Judge took judicial notice of some facts at the beginning of the trial. Which of the following is not an appropriate kind of fact for judicial notice?\n",
      "\n",
      "A) Indisputable facts.\n",
      "B) Facts recognized to be true by common knowledge.\n",
      "C) Facts that have been asserted by individual political organizations.\n",
      "D) Facts capable of scientific verification.\n",
      "\n",
      "Example Answer: {\"answer\": \"C\"}\n",
      "\n",
      "Example Question: A state legislature has recently enacted a statute making it a misdemeanor to curse or revile or use obscene or opprobrious language toward or in reference to a police officer perfonning his duties. A student at a state university organized a demonstration on campus to protest the war. The rally was attended by a group of 50 students who shouted anti-war messages at cars passing by. To show his contempt for the United States, the student sewed the American flag to the rear of his jeans. When a police officer saw the flag sown on the student's jeans, he approached and told him to remove the flag or he would be placed under arrest. The student became angered and shouted at the police officer, \"Listen, you bastard, I'll wear this rag anywhere I please. \" The student was subsequently placed under arrest and charged with violating the state statute. The student subsequently brings suit in state court challenging the constitutionality of the statute. The strongest constitutional argument for the student is that\n",
      "\n",
      "A) the statute is overbroad and consequently invalid under the First and FourteenthAmendments.\n",
      "B) the statute is invalid because it violates the petitioner's freedom of speech under the First Amendment.\n",
      "C) the statute is an abridgment of freedom of speech under the First Amendment because less restrictive means are available for achieving the same purpose.\n",
      "D) the statute is void for vagueness under the Fourteenth Amendment's due process clause.\n",
      "\n",
      "Example Answer: {\"answer\": \"A\"}\n",
      "\n",
      "Example Question: On October 1, 1980, a developer, owner of several hundred acres in a rural county, drafted a general development plan for the area. The duly recorded plan imposed elaborate limitations and restrictions upon the land in the plan, which was to be developed as a residential district. The restrictions were to extend to all persons acquiring any of the lots and to their heirs, assigns, and lessees. It was further provided that all subsequent owners would be charged with due notice of the restrictions. Among those restrictions in the general plan were the following:(22) A franchise right is created in a strip of land 10 feet in width along the rear of each lot for the use of public utility companies with right of ingress and egress. (23) No house or structure of any kind shall be built on the aforementioned strip of land running through the said blocks. In 2000, a retiree purchased one of the lots, built a house, and erected a fence in the rear of his property within the restricted area. In 2004, a teacher purchased a lot adjacent to the retiree's property and built a new house. Two years later, a librarian purchased the lot that adjoined the teacher's property. The three deeds to those properties each contained references to the deed book where the general plan was recorded. In 2008, the librarian began the construction of a seven-foot post-and-rail fence along the line dividing his lot with the teacher's, and along the center of the area subject to the franchise right. Although the teacher objected to its construction, the fence was completed. If the teacher seeks a mandatory injunction to compel removal of the librarian's fence, the court will most likely\n",
      "\n",
      "A) grant relief, because the fence was in violation of the easement restriction. \n",
      "B) grant relief, because the encroachment of the fence violated the restriction in the original plan. \n",
      "C) deny relief, because the teacher failed to enforce the restriction against the retiree. \n",
      "D) deny relief, because the fence would not be construed as \"a structure\" within the terms of the restriction. \n",
      "\n",
      "Example Answer: {\"answer\": \"B\"}\n",
      "\n",
      "Example Question: A son owed a creditor $5,000. The son's father contacted the creditor and told him that he wanted to pay the son's debt. The father signed a document that stated the father would pay the son's debt at a rate of $500 a month for 10 months. The creditor made no written or oral commitment to forbear to sue the son to collect the $5,000 debt, and the father made no oral or written request for any such forbearance. For the next five months, the father made and the creditor accepted the $500 monthly payments as agreed. During that period, the creditor, in fact, did forbear to take any legal action against the son. However, the father then informed the creditor that he would make no further payments on the debt. Which of the following is the most persuasive argument that the father is liable to the creditor under the terms of their agreement?\n",
      "\n",
      "A) By assuming the antecedent debt obligation that the son owed to the creditor, the father became a surety whose promise to the creditor was enforceable, since it was in writing and supported by adequate consideration. \n",
      "B) Because it was foreseeable that the father's promise would induce the creditor to forbear taking any action against the son, such forbearance was, as a matter of law, a bargained-for consideration for the father's promise. \n",
      "C) The father's five payments to the creditor totaling $2,500 manifested a serious intent on the father's part to be contractually bound, and such manifestation is generally recognized as an effective substitute for consideration. \n",
      "D) The father's promise and the creditor's reliance thereon, if proved, gave rise to a valid claim by the creditor against the father based on the doctrine of promissory estoppel. \n",
      "\n",
      "Example Answer: {\"answer\": \"D\"}\n",
      "\n",
      "Given the examples above, your task is to answer the following question.\n",
      "\n",
      "Question: A man, his brother and his friend all discuss murdering the man's neighbor because the neighbor took some shots at the man's dog but he missed. They agree on a plan. They decided on strychnine poisoning, which the friend told them how to get and they went and got it. When they asked the friend to go forward in poisoning the victim, he refused, saying, \"I'm was only here for planning and advice, but I never intended to commit murder.\" The man and his brother took the poison to a meeting with the neighbor, but he wouldn't drink. They were caught and arrested. The statute requires an overt act for criminal conspiracy. Which of the following most accurately states the criminal responsibility of each of the three men?\n",
      "\n",
      "A) The man and his brother have committed criminal conspiracy and attempted murder.\n",
      "B) The man and his brother are guilty of conspiracy but not attempted murder.\n",
      "C) The man and his brother are guilty of conspiracy and attempted murder, and the friend is guilty of criminal conspiracy.\n",
      "D) The man and his brother are guilty of conspiracy and attempted murder, but the friend is guilty of nothing.\n",
      "\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "# Print example prompt\n",
    "print(lmb.datasets.mmlu.generate_prompt(examples, selected_questions.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0c1ff00-a43e-41d1-9c89-6e6642f09620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.59it/s]\n",
      "epoch 1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.40it/s]\n",
      "epoch 2: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                      \n",
       " <span style=\"font-weight: bold\"> n  </span> <span style=\"font-weight: bold\"> correct </span> <span style=\"font-weight: bold\"> errors </span> <span style=\"font-weight: bold\"> accuracy </span> <span style=\"font-weight: bold\"> error_rate </span> <span style=\"font-weight: bold\"> rps                </span> \n",
       " ──────────────────────────────────────────────────────────────────── \n",
       "  16   9         0        0.5625     0.0          1.5845044835437943  \n",
       "  16   9         0        0.5625     0.0          1.3990426351247842  \n",
       "  16   9         0        0.5625     0.0          1.3975357826979047  \n",
       "                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                                                      \n",
       " \u001b[1m \u001b[0m\u001b[1mn \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mcorrect\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merrors\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1maccuracy\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merror_rate\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mrps               \u001b[0m\u001b[1m \u001b[0m \n",
       " ──────────────────────────────────────────────────────────────────── \n",
       "  16   9         0        0.5625     0.0          1.5845044835437943  \n",
       "  16   9         0        0.5625     0.0          1.3990426351247842  \n",
       "  16   9         0        0.5625     0.0          1.3975357826979047  \n",
       "                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 132 ms, sys: 27.2 ms, total: 160 ms\n",
      "Wall time: 33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rows = []\n",
    "for i in range(n_epochs):\n",
    "\n",
    "    # Run benchmark\n",
    "    metrics = benchmark(\n",
    "        f\"epoch {i}\", \n",
    "        examples=examples, \n",
    "        questions=selected_questions, \n",
    "        generator_options=llm_options,\n",
    "    )\n",
    "    \n",
    "    rows.append(metrics)\n",
    "\n",
    "print_table(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c39e34-9333-4798-b059-b55748fbcade",
   "metadata": {},
   "source": [
    "## Estimate Positional Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af877f4d-2cc3-40b3-8a92-3ad28e5e0a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uniform: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [03:05<00:00,  1.29it/s]\n",
      "B: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [03:05<00:00,  1.29it/s]\n",
      "C: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [03:03<00:00,  1.31it/s]\n",
      "D: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [03:07<00:00,  1.28it/s]\n",
      "A: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [03:07<00:00,  1.28it/s]\n",
      "uniform: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [03:11<00:00,  1.25it/s]\n",
      "B: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [03:10<00:00,  1.26it/s]\n",
      "C: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [03:12<00:00,  1.25it/s]\n",
      "D: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [03:09<00:00,  1.27it/s]\n",
      "A: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [03:10<00:00,  1.26it/s]\n",
      "uniform: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [03:28<00:00,  1.15it/s]\n",
      "B: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [03:28<00:00,  1.15it/s]\n",
      "C: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [03:29<00:00,  1.15it/s]\n",
      "D: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [03:26<00:00,  1.16it/s]\n",
      "A: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [03:22<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.21 s, sys: 971 ms, total: 9.18 s\n",
      "Wall time: 48min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Repeat over multiple iterations\n",
    "rows = []\n",
    "for _ in range(n_epochs):\n",
    "    \n",
    "    # Sample questions\n",
    "    selected_questions = questions.sample(n=n_questions)\n",
    "    \n",
    "    # Debias answer distribution\n",
    "    selected_questions = lmb.datasets.mmlu.normalize_question_answers(selected_questions)\n",
    "    \n",
    "    # Initialize metrics\n",
    "    metrics = {}\n",
    "    \n",
    "    # Record performance w/ original data\n",
    "    metrics[\"uniform\"] = benchmark(\n",
    "        \"uniform\", \n",
    "        examples=examples, \n",
    "        questions=selected_questions, \n",
    "        generator_options=llm_options,\n",
    "    )\n",
    "\n",
    "    # Record performance w/ answers shifted to each position\n",
    "    for option in OPTIONS:\n",
    "        # Swap answers to selected option\n",
    "        q = lmb.datasets.mmlu.swap_options(selected_questions, option)\n",
    "        \n",
    "        metrics[option] = benchmark(\n",
    "            option, \n",
    "            examples=examples, \n",
    "            questions=q, \n",
    "            generator_options=llm_options,\n",
    "        )\n",
    "\n",
    "    rows.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7cf71dd-01e1-42e7-ab66-798960c4b2e4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                          \n",
       " <span style=\"font-weight: bold\"> uniform </span> <span style=\"font-weight: bold\"> A     </span> <span style=\"font-weight: bold\"> B    </span> <span style=\"font-weight: bold\"> C     </span> <span style=\"font-weight: bold\"> D     </span> \n",
       " ──────────────────────────────────────── \n",
       "  0.55      <span style=\"color: #000000; text-decoration-color: #000000\">-0.02</span>   <span style=\"color: #000000; text-decoration-color: #000000\">0.05</span>   <span style=\"color: #000000; text-decoration-color: #000000\">0.04</span>    <span style=\"color: #800000; text-decoration-color: #800000\">-0.10</span>  \n",
       "  0.57      <span style=\"color: #000000; text-decoration-color: #000000\">-0.06</span>   <span style=\"color: #000000; text-decoration-color: #000000\">0.09</span>   <span style=\"color: #000000; text-decoration-color: #000000\">-0.03</span>   <span style=\"color: #800000; text-decoration-color: #800000\">-0.13</span>  \n",
       "  0.56      <span style=\"color: #000000; text-decoration-color: #000000\">0.04</span>    <span style=\"color: #000000; text-decoration-color: #000000\">0.08</span>   <span style=\"color: #000000; text-decoration-color: #000000\">0.01</span>    <span style=\"color: #800000; text-decoration-color: #800000\">-0.11</span>  \n",
       "                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                          \n",
       " \u001b[1m \u001b[0m\u001b[1muniform\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mA    \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mB   \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mC    \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mD    \u001b[0m\u001b[1m \u001b[0m \n",
       " ──────────────────────────────────────── \n",
       "  0.55      \u001b[30m-0.02\u001b[0m   \u001b[30m0.05\u001b[0m   \u001b[30m0.04\u001b[0m    \u001b[31m-0.10\u001b[0m  \n",
       "  0.57      \u001b[30m-0.06\u001b[0m   \u001b[30m0.09\u001b[0m   \u001b[30m-0.03\u001b[0m   \u001b[31m-0.13\u001b[0m  \n",
       "  0.56      \u001b[30m0.04\u001b[0m    \u001b[30m0.08\u001b[0m   \u001b[30m0.01\u001b[0m    \u001b[31m-0.11\u001b[0m  \n",
       "                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = Table(\"uniform\", \"A\", \"B\", \"C\", \"D\", box=rich.box.SIMPLE)\n",
    "for row in rows:\n",
    "    baseline = row[\"uniform\"][\"accuracy\"]\n",
    "    offsets = {k: row[k][\"accuracy\"] - baseline for k in OPTIONS}\n",
    "    colors = {option: \"black\" for option in OPTIONS}\n",
    "    colors |= {option: \"red\" for option in OPTIONS if offsets[option] <= -0.1}\n",
    "    colors |= {option: \"green\" for option in OPTIONS if offsets[option] >= 0.1}\n",
    "    table.add_row(\n",
    "        f\"{baseline:0.2f}\", \n",
    "        f\"[{colors[\"A\"]}]{offsets[\"A\"]:0.2f}[/{colors[\"A\"]}]\", \n",
    "        f\"[{colors[\"B\"]}]{offsets[\"B\"]:0.2f}[/{colors[\"B\"]}]\", \n",
    "        f\"[{colors[\"C\"]}]{offsets[\"C\"]:0.2f}[/{colors[\"C\"]}]\", \n",
    "        f\"[{colors[\"D\"]}]{offsets[\"D\"]:0.2f}[/{colors[\"D\"]}]\", \n",
    "    )\n",
    "\n",
    "rich.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4afebb-965d-43a9-9add-c512fb43386c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a8cfc-cc6e-410f-8bec-264b152f5e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f572b4-a72f-4581-8519-415d00e8dac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df4207d-7cf3-4eaf-9291-1fbfcc5729fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e3f48-eb24-4c3a-a4bd-38341b4f7dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
