{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf3002f-3004-4fc6-90f1-0af07682b26e",
   "metadata": {},
   "source": [
    "# Demonstrate Positional Bias\n",
    "\n",
    "Our goal here is to quantify positional bias inherrent in our LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5dde05-1cdb-4b1b-9624-e848d0211089",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c16667-139d-4211-8ace-4c48419b614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import partial\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from time import perf_counter_ns as timer\n",
    "from uuid import uuid4\n",
    "\n",
    "from pandas import DataFrame, Series\n",
    "import rich\n",
    "from rich.table import Table\n",
    "from tqdm import tqdm\n",
    "\n",
    "import llm_mcq_bias as lmb\n",
    "from llm_mcq_bias.datasets.mmlu import Evaluation, OPTIONS\n",
    "from llm_mcq_bias.models import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9972849e-862d-44be-bdff-6299e8e152fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def print_table(rows, title: str | None = None):\n",
    "    table = Table(*[k for k in rows[0]], title=title, box=rich.box.SIMPLE)\n",
    "    for row in rows:\n",
    "        table.add_row(*[str(v) for v in row.values()])\n",
    "    rich.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52d9ede7-ba69-4129-8c04-e1c5cda116f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to project root\n",
    "os.chdir(\"..\")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b09bb2-0aeb-436a-a111-0fc4b0c5899f",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "743d6fea-a824-4fdc-952a-275fdb0d94e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provider config\n",
    "providers = {\n",
    "    \"ollama\": {\n",
    "        \"model\": \"llama3.2:3b\",\n",
    "        \"options\": {\n",
    "            \"num_predict\": 10,  # Limit output tokens to avoid waiting for invalid responses\n",
    "            \"top_k\": 1,  # Disable token sampling\n",
    "        },\n",
    "        \"generator_factory\": lmb.models.ollama,\n",
    "    },\n",
    "    \"openai\": {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"options\": {\n",
    "            \"max_tokens\": 10,  # Limit output tokens to avoid waiting for invalid responses\n",
    "            \"temperature\": 0,  # Disable token sampling\n",
    "        },\n",
    "        \"generator_factory\": lmb.models.openai,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Selected provider\n",
    "provider = \"ollama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff5e6367-2ec9-40b3-ab6a-ef10259005a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations\n",
    "n_epochs = 1\n",
    "\n",
    "# Number of questions to sample\n",
    "n_questions = 16\n",
    "\n",
    "# Number of parallel requests\n",
    "n_jobs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac59e38-4538-416b-bc05-a441ff8a36bc",
   "metadata": {},
   "source": [
    "# Demonstrate Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef74a8b5-342f-4fe3-820d-a58ce0f06569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured ollama provider: llama3.2:3b, {'num_predict': 10, 'top_k': 1}\n"
     ]
    }
   ],
   "source": [
    "dataset_path = Path(\".build\") / \"datasets\" / \"mmlu\"\n",
    "\n",
    "# Load example questions\n",
    "examples = lmb.datasets.mmlu.load_dataset(dataset_path, segment=\"dev\")\n",
    "\n",
    "# Debias example answer distribution\n",
    "examples = lmb.datasets.mmlu.normalize_example_answers(examples)\n",
    "\n",
    "# Load test questions\n",
    "questions = lmb.datasets.mmlu.load_dataset(dataset_path, segment=\"test\")\n",
    "\n",
    "# Initialize thread pool\n",
    "executor = ThreadPoolExecutor(max_workers=n_jobs)\n",
    "\n",
    "# Create generator from provider\n",
    "generator_factory = providers[provider][\"generator_factory\"]\n",
    "model = providers[provider][\"model\"]\n",
    "options = providers[provider][\"options\"]\n",
    "generator = partial(generator_factory, model=model, options=options)\n",
    "\n",
    "print(f\"Configured {provider} provider: {model}, {options}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2bd801b-7838-4763-ad8e-564fc6655a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(\n",
    "    *,\n",
    "    examples: DataFrame, \n",
    "    mcq: Series, \n",
    "    generator: Generator,\n",
    "):\n",
    "    \"\"\"Answer a question.\"\"\"\n",
    "    \n",
    "    # Generate prompt\n",
    "    prompt = lmb.datasets.mmlu.generate_prompt(examples, mcq)\n",
    "\n",
    "    # Generate answer\n",
    "    answer = generator(prompt=prompt)\n",
    "\n",
    "    # Evaluate answer\n",
    "    return lmb.datasets.mmlu.evaluate_answer(mcq, answer)\n",
    "\n",
    "\n",
    "def benchmark(\n",
    "    description: str,\n",
    "    *,\n",
    "    examples: DataFrame,\n",
    "    questions: DataFrame,\n",
    "    generator: Generator,\n",
    "):\n",
    "    \"\"\"Run experiment.\"\"\"\n",
    "    \n",
    "    n = len(questions)\n",
    "\n",
    "    start_time = timer()\n",
    "\n",
    "    # Answer and evaluate each question in parallel\n",
    "    futures = [\n",
    "        executor.submit(\n",
    "            answer_question, \n",
    "            examples=examples, \n",
    "            mcq=mcq, \n",
    "            generator=generator,\n",
    "        ) for _, mcq in questions.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Collect results\n",
    "    correct, errors = 0, 0\n",
    "    for future in tqdm(as_completed(futures), total=n, desc=description):\n",
    "        evaluation = future.result()\n",
    "        if evaluation is Evaluation.CORRECT:\n",
    "            correct += 1\n",
    "        elif evaluation is Evaluation.ERROR:\n",
    "            errors += 1\n",
    "\n",
    "    duration = timer() - start_time\n",
    "\n",
    "    # Derive metrics\n",
    "    metrics = {\n",
    "        \"n\": n,\n",
    "        \"correct\": correct,\n",
    "        \"errors\": errors,\n",
    "        \"accuracy\": correct / (n - errors),\n",
    "        \"error_rate\": errors / n,\n",
    "        \"rps\": 1000000000 * n / duration,\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725062b-af28-465e-9e63-ed811d778d04",
   "metadata": {},
   "source": [
    "### Verify Stable Benchmark Results\n",
    "\n",
    "Let's make sure our benchmark process produces consistent results when run against the same inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc163e0-0718-4d08-b107-08424c406df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='answer'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample questions\n",
    "selected_questions = questions.sample(n=16)\n",
    "\n",
    "# Debias answer distribution\n",
    "selected_questions = lmb.datasets.mmlu.normalize_question_answers(selected_questions)\n",
    "\n",
    "# Plot answer distribution\n",
    "selected_questions.answer.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fafbe10b-2249-435a-950c-d716b4ab8fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a robot that only outputs JSON. You reply in JSON format with the field 'answer'. For example, the following are multiple choice questions about miscellaneous.\n",
      "\n",
      "Example Question: What is produced during photosynthesis?\n",
      "\n",
      "A) hydrogen\n",
      "B) nylon\n",
      "C) light\n",
      "D) oxygen\n",
      "\n",
      "Example Answer: {\"answer\": \"D\"}\n",
      "\n",
      "Example Question: Who is the shortest man to ever win an NBA slam dunk competition?\n",
      "\n",
      "A) Anthony 'Spud' Webb\n",
      "B) Michael 'Air' Jordan\n",
      "C) Tyrone 'Muggsy' Bogues\n",
      "D) Julius 'Dr J' Erving\n",
      "\n",
      "Example Answer: {\"answer\": \"A\"}\n",
      "\n",
      "Example Question: What place is named in the title of the 1979 live album by rock legends Cheap Trick?\n",
      "\n",
      "A) Budapest\n",
      "B) Bhutan\n",
      "C) Budokan\n",
      "D) Britain\n",
      "\n",
      "Example Answer: {\"answer\": \"C\"}\n",
      "\n",
      "Example Question: Which of these songs was a Top 10 hit for the rock band The Police?\n",
      "\n",
      "A) 'Radio Ga-Ga'\n",
      "B) 'De Do Do Do De Da Da Da'\n",
      "C) 'Ob-la-di Ob-la-da'\n",
      "D) 'In-a-Gadda-Da-Vida'\n",
      "\n",
      "Example Answer: {\"answer\": \"B\"}\n",
      "\n",
      "Given the examples above, your task is to answer the following question.\n",
      "\n",
      "Question: Who is considered the owner of a 'publicly held' company?\n",
      "\n",
      "A) the CEO\n",
      "B) the president\n",
      "C) the stockholders\n",
      "D) the government\n",
      "\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "# Print example prompt\n",
    "print(lmb.datasets.mmlu.generate_prompt(examples, selected_questions.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0c1ff00-a43e-41d1-9c89-6e6642f09620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:13<00:00,  1.15it/s]\n",
      "epoch 1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:14<00:00,  1.09it/s]\n",
      "epoch 2: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:14<00:00,  1.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                                 \n",
       " <span style=\"font-weight: bold\"> n  </span> <span style=\"font-weight: bold\"> correct </span> <span style=\"font-weight: bold\"> errors </span> <span style=\"font-weight: bold\"> accuracy            </span> <span style=\"font-weight: bold\"> error_rate </span> <span style=\"font-weight: bold\"> rps                </span> \n",
       " ─────────────────────────────────────────────────────────────────────────────── \n",
       "  16   6         2        0.42857142857142855   0.125        1.1458013510412277  \n",
       "  16   6         2        0.42857142857142855   0.125        1.0916129765767404  \n",
       "  16   6         2        0.42857142857142855   0.125        1.0699108026270252  \n",
       "                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                                                                 \n",
       " \u001b[1m \u001b[0m\u001b[1mn \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mcorrect\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merrors\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1maccuracy           \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merror_rate\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mrps               \u001b[0m\u001b[1m \u001b[0m \n",
       " ─────────────────────────────────────────────────────────────────────────────── \n",
       "  16   6         2        0.42857142857142855   0.125        1.1458013510412277  \n",
       "  16   6         2        0.42857142857142855   0.125        1.0916129765767404  \n",
       "  16   6         2        0.42857142857142855   0.125        1.0699108026270252  \n",
       "                                                                                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 103 ms, sys: 24.1 ms, total: 127 ms\n",
      "Wall time: 43.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rows = []\n",
    "for i in range(3):\n",
    "    # Run benchmark\n",
    "    metrics = benchmark(\n",
    "        f\"epoch {i}\",\n",
    "        examples=examples,\n",
    "        questions=selected_questions,\n",
    "        generator=generator\n",
    "    )\n",
    "\n",
    "    rows.append(metrics)\n",
    "\n",
    "print_table(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c39e34-9333-4798-b059-b55748fbcade",
   "metadata": {},
   "source": [
    "## Estimate Positional Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af877f4d-2cc3-40b3-8a92-3ad28e5e0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Repeat over multiple iterations\n",
    "rows = []\n",
    "for _ in range(n_epochs):\n",
    "    # Sample questions\n",
    "    selected_questions = questions.sample(n=n_questions)\n",
    "\n",
    "    # Debias answer distribution\n",
    "    selected_questions = lmb.datasets.mmlu.normalize_question_answers(\n",
    "        selected_questions\n",
    "    )\n",
    "\n",
    "    # Initialize metrics\n",
    "    metrics = {}\n",
    "\n",
    "    # Record performance w/ original data\n",
    "    metrics[\"uniform\"] = benchmark(\n",
    "        \"uniform\",\n",
    "        examples=examples,\n",
    "        questions=selected_questions,\n",
    "    )\n",
    "\n",
    "    # Record performance w/ answers shifted to each position\n",
    "    for option in OPTIONS:\n",
    "        # Swap answers to selected option\n",
    "        q = lmb.datasets.mmlu.swap_options(selected_questions, option)\n",
    "\n",
    "        metrics[option] = benchmark(\n",
    "            option,\n",
    "            examples=examples,\n",
    "            questions=q,\n",
    "        )\n",
    "\n",
    "    rows.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf71dd-01e1-42e7-ab66-798960c4b2e4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "table = Table(\"uniform\", \"A\", \"B\", \"C\", \"D\", box=rich.box.SIMPLE)\n",
    "for row in rows:\n",
    "    baseline = row[\"uniform\"][\"accuracy\"]\n",
    "    offsets = {k: row[k][\"accuracy\"] - baseline for k in OPTIONS}\n",
    "    colors = {option: \"black\" for option in OPTIONS}\n",
    "    colors |= {option: \"red\" for option in OPTIONS if offsets[option] <= -0.05}\n",
    "    colors |= {option: \"green\" for option in OPTIONS if offsets[option] >= 0.05}\n",
    "    table.add_row(\n",
    "        f\"{baseline:0.2f}\",\n",
    "        f\"[{colors['A']}]{offsets['A']:0.2f}[/{colors['A']}]\",\n",
    "        f\"[{colors['B']}]{offsets['B']:0.2f}[/{colors['B']}]\",\n",
    "        f\"[{colors['C']}]{offsets['C']:0.2f}[/{colors['C']}]\",\n",
    "        f\"[{colors['D']}]{offsets['D']:0.2f}[/{colors['D']}]\",\n",
    "    )\n",
    "\n",
    "rich.print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940a7c2e-c8f3-465b-b68e-8f78f88e9171",
   "metadata": {},
   "source": [
    "# Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a8cfc-cc6e-410f-8bec-264b152f5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(f\"results/demonstrate-bias-{model}-{n_questions}-{n_epochs}-{uuid4().hex}.json\")\n",
    "path.write_text(json.dumps(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df4207d-7cf3-4eaf-9291-1fbfcc5729fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e3f48-eb24-4c3a-a4bd-38341b4f7dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
