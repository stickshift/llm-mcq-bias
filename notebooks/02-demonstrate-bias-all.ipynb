{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf3002f-3004-4fc6-90f1-0af07682b26e",
   "metadata": {},
   "source": [
    "# Demonstrate Positional Bias\n",
    "\n",
    "Our goal here is to quantify positional bias inherrent in our LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5dde05-1cdb-4b1b-9624-e848d0211089",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c16667-139d-4211-8ace-4c48419b614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import partial\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from time import perf_counter_ns as timer\n",
    "from uuid import uuid4\n",
    "\n",
    "from pandas import DataFrame, Series\n",
    "import rich\n",
    "from rich.table import Table\n",
    "from tqdm import tqdm\n",
    "\n",
    "import llm_mcq_bias as lmb\n",
    "from llm_mcq_bias.datasets.mmlu import Evaluation, OPTIONS\n",
    "from llm_mcq_bias.models import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9972849e-862d-44be-bdff-6299e8e152fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def print_table(rows, title: str | None = None):\n",
    "    table = Table(*[k for k in rows[0]], title=title, box=rich.box.SIMPLE)\n",
    "    for row in rows:\n",
    "        table.add_row(*[str(v) for v in row.values()])\n",
    "    rich.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52d9ede7-ba69-4129-8c04-e1c5cda116f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to project root\n",
    "os.chdir(\"..\")\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b09bb2-0aeb-436a-a111-0fc4b0c5899f",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "743d6fea-a824-4fdc-952a-275fdb0d94e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provider config\n",
    "providers = {\n",
    "    \"ollama\": {\n",
    "        \"model\": \"llama3.2:3b\",\n",
    "        \"options\": {\n",
    "            \"num_predict\": 10,  # Limit output tokens to avoid waiting for invalid responses\n",
    "            \"top_k\": 1,  # Disable token sampling\n",
    "        },\n",
    "        \"generator_factory\": lmb.models.ollama,\n",
    "    },\n",
    "    \"openai\": {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"options\": {\n",
    "            \"max_tokens\": 10,  # Limit output tokens to avoid waiting for invalid responses\n",
    "            \"temperature\": 0,  # Disable token sampling\n",
    "        },\n",
    "        \"generator_factory\": lmb.models.openai,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Selected provider\n",
    "provider = \"ollama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff5e6367-2ec9-40b3-ab6a-ef10259005a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations\n",
    "n_epochs = 1\n",
    "\n",
    "# Number of questions to sample\n",
    "n_questions = 16\n",
    "\n",
    "# Number of parallel requests\n",
    "n_jobs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac59e38-4538-416b-bc05-a441ff8a36bc",
   "metadata": {},
   "source": [
    "# Demonstrate Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef74a8b5-342f-4fe3-820d-a58ce0f06569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured ollama provider: llama3.2:3b, {'num_predict': 10, 'top_k': 1}\n"
     ]
    }
   ],
   "source": [
    "dataset_path = Path(\".build\") / \"datasets\" / \"mmlu\"\n",
    "\n",
    "# Load example questions\n",
    "examples = lmb.datasets.mmlu.load_dataset(dataset_path, segment=\"dev\")\n",
    "\n",
    "# Debias example answer distribution\n",
    "examples = lmb.datasets.mmlu.debias_example_answers(examples)\n",
    "\n",
    "# Load test questions\n",
    "questions = lmb.datasets.mmlu.load_dataset(dataset_path, segment=\"test\")\n",
    "\n",
    "# Initialize thread pool\n",
    "executor = ThreadPoolExecutor(max_workers=n_jobs)\n",
    "\n",
    "# Create generator from provider\n",
    "generator_factory = providers[provider][\"generator_factory\"]\n",
    "model = providers[provider][\"model\"]\n",
    "options = providers[provider][\"options\"]\n",
    "generator = partial(generator_factory, model=model, options=options)\n",
    "\n",
    "print(f\"Configured {provider} provider: {model}, {options}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2bd801b-7838-4763-ad8e-564fc6655a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(\n",
    "    *,\n",
    "    examples: DataFrame, \n",
    "    mcq: Series, \n",
    "    generator: Generator,\n",
    "):\n",
    "    \"\"\"Answer a question.\"\"\"\n",
    "    \n",
    "    # Generate prompt\n",
    "    prompt = lmb.datasets.mmlu.generate_prompt(examples, mcq)\n",
    "\n",
    "    # Generate answer\n",
    "    answer = generator(prompt=prompt)\n",
    "\n",
    "    # Evaluate answer\n",
    "    return lmb.datasets.mmlu.evaluate_answer(mcq, answer)\n",
    "\n",
    "\n",
    "def benchmark(\n",
    "    description: str,\n",
    "    *,\n",
    "    examples: DataFrame,\n",
    "    questions: DataFrame,\n",
    "    generator: Generator,\n",
    "):\n",
    "    \"\"\"Run experiment.\"\"\"\n",
    "    \n",
    "    n = len(questions)\n",
    "\n",
    "    start_time = timer()\n",
    "\n",
    "    # Answer and evaluate each question in parallel\n",
    "    futures = [\n",
    "        executor.submit(\n",
    "            answer_question, \n",
    "            examples=examples, \n",
    "            mcq=mcq, \n",
    "            generator=generator,\n",
    "        ) for _, mcq in questions.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Collect results\n",
    "    correct, errors = 0, 0\n",
    "    for future in tqdm(as_completed(futures), total=n, desc=description):\n",
    "        evaluation = future.result()\n",
    "        if evaluation is Evaluation.CORRECT:\n",
    "            correct += 1\n",
    "        elif evaluation is Evaluation.ERROR:\n",
    "            errors += 1\n",
    "\n",
    "    duration = timer() - start_time\n",
    "\n",
    "    # Derive metrics\n",
    "    metrics = {\n",
    "        \"n\": n,\n",
    "        \"correct\": correct,\n",
    "        \"errors\": errors,\n",
    "        \"accuracy\": correct / (n - errors),\n",
    "        \"error_rate\": errors / n,\n",
    "        \"rps\": 1000000000 * n / duration,\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725062b-af28-465e-9e63-ed811d778d04",
   "metadata": {},
   "source": [
    "### Verify Stable Benchmark Results\n",
    "\n",
    "Let's make sure our benchmark process produces consistent results when run against the same inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc163e0-0718-4d08-b107-08424c406df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='answer'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample questions\n",
    "selected_questions = questions.sample(n=16)\n",
    "\n",
    "# Debias answer distribution\n",
    "selected_questions = lmb.datasets.mmlu.debias_question_answers(selected_questions)\n",
    "\n",
    "# Plot answer distribution\n",
    "selected_questions.answer.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fafbe10b-2249-435a-950c-d716b4ab8fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a robot that only outputs JSON. You reply in JSON format with the field 'answer'. For example, the following are multiple choice questions about formal logic.\n",
      "\n",
      "Example Question:  Select the best English interpretation of the given arguments in predicate logic.\n",
      "Dm\n",
      "(∀x)(Wx ⊃ ~Dx)\n",
      "(∀x)Wx ∨ Ag\t/ (∃x)Ax\n",
      "\n",
      "A) Marina is a dancer. No weakling is a dancer. Either everything is a weakling or Georgia plays volleyball. So something plays volleyball.\n",
      "B) Marina is a dancer. No weakling is a dancer. Everything is either a weakling or plays volleyball. So something plays volleyball.\n",
      "C) Marina is a dancer. Some weaklings are not dancers. Everything is either a weakling or plays volleyball. So something plays volleyball.\n",
      "D) Marina is a dancer. Some weaklings are not dancers. Either everything is a weakling or Georgia plays volleyball. So something plays volleyball.\n",
      "\n",
      "Example Answer: {\"answer\": \"A\"}\n",
      "\n",
      "Example Question:  Construct a complete truth table for the following pairs of propositions. Then, using the truth tables, determine whether the statements are logically equivalent or contradictory. If neither, determine whether they are consistent or inconsistent. Justify your answers.\n",
      "E ⊃ (F · E) and ~E · F\n",
      "\n",
      "A) Logically equivalent\n",
      "B) Neither logically equivalent nor contradictory, but consistent\n",
      "C) Contradictory\n",
      "D) Inconsistent\n",
      "\n",
      "Example Answer: {\"answer\": \"B\"}\n",
      "\n",
      "Example Question: Select the best translation into predicate logic.George borrows Hector's lawnmower. (g: George; h: Hector; l: Hector's lawnmower; Bxyx: x borrows y from z)\n",
      "\n",
      "A) Blgh\n",
      "B) Bhlg\n",
      "C) Bghl\n",
      "D) Bglh\n",
      "\n",
      "Example Answer: {\"answer\": \"D\"}\n",
      "\n",
      "Example Question:  Which of the given formulas of PL is the best symbolization of the following sentence?\n",
      "Turtles live long lives and are happy creatures, unless they are injured.\n",
      "\n",
      "A) (L • H) ≡ I\n",
      "B) L • (H ∨ I)\n",
      "C) (L • H) ∨ I\n",
      "D) L • (H ⊃ R)\n",
      "\n",
      "Example Answer: {\"answer\": \"C\"}\n",
      "\n",
      "Given the examples above, your task is to answer the following question.\n",
      "\n",
      "Question:  Construct a complete truth table for the following pairs of propositions. Then, using the truth tables, determine whether the statements are logically equivalent or contradictory. If neither, determine whether they are consistent or inconsistent. Justify your answers.\n",
      "(G ∨ ~H) ⊃ G and ~G ≡ (~H · G)\n",
      "\n",
      "A) Logically equivalent\n",
      "B) Contradictory\n",
      "C) Neither logically equivalent nor contradictory, but consistent\n",
      "D) Inconsistent\n",
      "\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "# Print example prompt\n",
    "print(lmb.datasets.mmlu.generate_prompt(examples, selected_questions.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0c1ff00-a43e-41d1-9c89-6e6642f09620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:10<00:00,  1.46it/s]\n",
      "epoch 1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.43it/s]\n",
      "epoch 2: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:11<00:00,  1.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                                      \n",
       " <span style=\"font-weight: bold\"> n  </span> <span style=\"font-weight: bold\"> correct </span> <span style=\"font-weight: bold\"> errors </span> <span style=\"font-weight: bold\"> accuracy </span> <span style=\"font-weight: bold\"> error_rate </span> <span style=\"font-weight: bold\"> rps                </span> \n",
       " ──────────────────────────────────────────────────────────────────── \n",
       "  16   8         0        0.5        0.0          1.4564757760458655  \n",
       "  16   8         0        0.5        0.0          1.4299601017671324  \n",
       "  16   8         0        0.5        0.0          1.3902359565708458  \n",
       "                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                                                      \n",
       " \u001b[1m \u001b[0m\u001b[1mn \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mcorrect\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merrors\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1maccuracy\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1merror_rate\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mrps               \u001b[0m\u001b[1m \u001b[0m \n",
       " ──────────────────────────────────────────────────────────────────── \n",
       "  16   8         0        0.5        0.0          1.4564757760458655  \n",
       "  16   8         0        0.5        0.0          1.4299601017671324  \n",
       "  16   8         0        0.5        0.0          1.3902359565708458  \n",
       "                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 104 ms, sys: 30 ms, total: 134 ms\n",
      "Wall time: 33.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rows = []\n",
    "for i in range(3):\n",
    "    # Run benchmark\n",
    "    metrics = benchmark(\n",
    "        f\"epoch {i}\",\n",
    "        examples=examples,\n",
    "        questions=selected_questions,\n",
    "        generator=generator\n",
    "    )\n",
    "\n",
    "    rows.append(metrics)\n",
    "\n",
    "print_table(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c39e34-9333-4798-b059-b55748fbcade",
   "metadata": {},
   "source": [
    "## Estimate Positional Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af877f4d-2cc3-40b3-8a92-3ad28e5e0a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uniform: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:12<00:00,  1.27it/s]\n",
      "A: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:13<00:00,  1.21it/s]\n",
      "B: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:13<00:00,  1.19it/s]\n",
      "D: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:13<00:00,  1.15it/s]\n",
      "C: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:13<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 158 ms, sys: 22.5 ms, total: 180 ms\n",
      "Wall time: 1min 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Repeat over multiple iterations\n",
    "rows = []\n",
    "for _ in range(n_epochs):\n",
    "    # Sample questions\n",
    "    selected_questions = questions.sample(n=n_questions)\n",
    "\n",
    "    # Debias answer distribution\n",
    "    selected_questions = lmb.datasets.mmlu.debias_question_answers(selected_questions)\n",
    "\n",
    "    # Initialize metrics\n",
    "    metrics = {}\n",
    "\n",
    "    # Record performance w/ original data\n",
    "    metrics[\"U\"] = benchmark(\n",
    "        \"U\",\n",
    "        examples=examples,\n",
    "        questions=selected_questions,\n",
    "        generator=generator\n",
    "    )\n",
    "\n",
    "    # Record performance w/ answers shifted to each position\n",
    "    for option in OPTIONS:\n",
    "        # Swap answers to selected option\n",
    "        q = lmb.datasets.mmlu.swap_options(selected_questions, option)\n",
    "\n",
    "        metrics[option] = benchmark(\n",
    "            option,\n",
    "            examples=examples,\n",
    "            questions=q,\n",
    "            generator=generator\n",
    "        )\n",
    "\n",
    "    rows.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7cf71dd-01e1-42e7-ab66-798960c4b2e4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                           \n",
       " <span style=\"font-weight: bold\"> uniform </span> <span style=\"font-weight: bold\"> A </span> <span style=\"font-weight: bold\"> B </span> <span style=\"font-weight: bold\"> C </span> <span style=\"font-weight: bold\"> D </span> \n",
       " ───────────────────────── \n",
       "                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                           \n",
       " \u001b[1m \u001b[0m\u001b[1muniform\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mA\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mB\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mC\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mD\u001b[0m\u001b[1m \u001b[0m \n",
       " ───────────────────────── \n",
       "                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table = Table(\"uniform\", \"A\", \"B\", \"C\", \"D\", box=rich.box.SIMPLE)\n",
    "for row in rows:\n",
    "    baseline = row[\"uniform\"][\"accuracy\"]\n",
    "    offsets = {k: row[k][\"accuracy\"] - baseline for k in OPTIONS}\n",
    "    colors = {option: \"black\" for option in OPTIONS}\n",
    "    colors |= {option: \"red\" for option in OPTIONS if offsets[option] <= -0.05}\n",
    "    colors |= {option: \"green\" for option in OPTIONS if offsets[option] >= 0.05}\n",
    "    table.add_row(\n",
    "        f\"{baseline:0.2f}\",\n",
    "        f\"[{colors['A']}]{offsets['A']:0.2f}[/{colors['A']}]\",\n",
    "        f\"[{colors['B']}]{offsets['B']:0.2f}[/{colors['B']}]\",\n",
    "        f\"[{colors['C']}]{offsets['C']:0.2f}[/{colors['C']}]\",\n",
    "        f\"[{colors['D']}]{offsets['D']:0.2f}[/{colors['D']}]\",\n",
    "    )\n",
    "\n",
    "rich.print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940a7c2e-c8f3-465b-b68e-8f78f88e9171",
   "metadata": {},
   "source": [
    "# Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "000a8cfc-cc6e-410f-8bec-264b152f5e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = model.replace(\":\", \"-\")\n",
    "path = Path(f\"notebooks/results/order-dependency-{model_name}-{n_questions}-{n_epochs}-{uuid4().hex}.json\")\n",
    "path.write_text(json.dumps(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df4207d-7cf3-4eaf-9291-1fbfcc5729fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e3f48-eb24-4c3a-a4bd-38341b4f7dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
