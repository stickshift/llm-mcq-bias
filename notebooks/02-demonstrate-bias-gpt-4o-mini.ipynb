{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf3002f-3004-4fc6-90f1-0af07682b26e",
   "metadata": {},
   "source": [
    "# Demonstrate Positional Bias\n",
    "\n",
    "Our goal here is to quantify positional bias inherrent in our LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5dde05-1cdb-4b1b-9624-e848d0211089",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c16667-139d-4211-8ace-4c48419b614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from time import perf_counter_ns as timer\n",
    "\n",
    "from pandas import DataFrame\n",
    "import rich\n",
    "from rich.table import Table\n",
    "from tqdm import tqdm\n",
    "\n",
    "import llm_mcq_bias as lmb\n",
    "from llm_mcq_bias.datasets.mmlu import Evaluation, OPTIONS\n",
    "from llm_mcq_bias.models import gpt_4o_mini as generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9972849e-862d-44be-bdff-6299e8e152fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(rows, title: str | None = None):\n",
    "    table = Table(*[k for k in rows[0]], title=title, box=rich.box.SIMPLE)\n",
    "    for row in rows:\n",
    "        table.add_row(*[str(v) for v in row.values()])\n",
    "    rich.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52d9ede7-ba69-4129-8c04-e1c5cda116f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = Path(\"../\")\n",
    "datasets_path = project_path / \".build\" / \"datasets\"\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd3a0af-90a2-40cc-bdc2-7e52ff1da1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Boston'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warm up model\n",
    "generator(\n",
    "    prompt=\"What is the capital of Massachusetts? Answer in one word.\",\n",
    "    options={\"max_tokens\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac59e38-4538-416b-bc05-a441ff8a36bc",
   "metadata": {},
   "source": [
    "# Demonstrate Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d74b570-6ba6-4056-bef7-ef4e44515768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations\n",
    "n_epochs = 10\n",
    "\n",
    "# Number of questions to sample\n",
    "n_questions = 160\n",
    "\n",
    "# Number of workers\n",
    "n_jobs = 3\n",
    "\n",
    "llm_options = {\n",
    "    # Limit output tokens to avoid waiting for invalid responses\n",
    "    \"max_tokens\": 10,\n",
    "    # Disable token sampling\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef74a8b5-342f-4fe3-820d-a58ce0f06569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example questions\n",
    "examples = lmb.datasets.mmlu.load_dataset(datasets_path, segment=\"dev\")\n",
    "\n",
    "# Debias example answer distribution\n",
    "examples = lmb.datasets.mmlu.normalize_example_answers(examples)\n",
    "\n",
    "# Load test questions\n",
    "questions = lmb.datasets.mmlu.load_dataset(datasets_path, segment=\"test\")\n",
    "\n",
    "# Initialize thread pool\n",
    "executor = ThreadPoolExecutor(max_workers=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2bd801b-7838-4763-ad8e-564fc6655a64",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def process_mcq(generator, generator_options, mcq):\n",
    "    # Generate prompt\n",
    "    prompt = lmb.datasets.mmlu.generate_prompt(examples, mcq)\n",
    "\n",
    "    # Generate answer\n",
    "    response = generator(prompt=prompt, options=generator_options)\n",
    "\n",
    "    # Evaluate response\n",
    "    evaluation = lmb.datasets.mmlu.evaluate_response(mcq, response)\n",
    "\n",
    "    return evaluation\n",
    "\n",
    "\n",
    "def benchmark(\n",
    "    description: str,\n",
    "    *,\n",
    "    examples: DataFrame,\n",
    "    questions: DataFrame,\n",
    "    generator,\n",
    "    generator_options: dict,\n",
    "):\n",
    "    n = len(questions)\n",
    "\n",
    "    start_time = timer()\n",
    "\n",
    "    # Answer and evaluate each question\n",
    "    futures = [\n",
    "        executor.submit(process_mcq, generator, generator_options, mcq)\n",
    "        for _, mcq in questions.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Collect results\n",
    "    correct, errors = 0, 0\n",
    "    for future in tqdm(as_completed(futures), total=n, desc=description):\n",
    "        evaluation = future.result()\n",
    "        if evaluation is Evaluation.CORRECT:\n",
    "            correct += 1\n",
    "        elif evaluation is Evaluation.ERROR:\n",
    "            errors += 1\n",
    "\n",
    "    duration = timer() - start_time\n",
    "\n",
    "    # Derive metrics\n",
    "    metrics = {\n",
    "        \"n\": n,\n",
    "        \"correct\": correct,\n",
    "        \"errors\": errors,\n",
    "        \"accuracy\": correct / (n - errors),\n",
    "        \"error_rate\": errors / n,\n",
    "        \"rps\": 1000000000 * n / duration,\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725062b-af28-465e-9e63-ed811d778d04",
   "metadata": {},
   "source": [
    "### Verify Stable Benchmark Results\n",
    "\n",
    "Let's make sure our benchmark process produces consistent results when run against the same inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc163e0-0718-4d08-b107-08424c406df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='answer'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample questions\n",
    "selected_questions = questions.sample(n=16)\n",
    "\n",
    "# Debias answer distribution\n",
    "selected_questions = lmb.datasets.mmlu.normalize_question_answers(selected_questions)\n",
    "\n",
    "# Plot answer distribution\n",
    "selected_questions.answer.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fafbe10b-2249-435a-950c-d716b4ab8fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a robot that only outputs JSON. You reply in JSON format with the field 'answer'. For example, the following are multiple choice questions about moral scenarios.\n",
      "\n",
      "Example Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | I asked for a cigarette from the guy outside the store. Scenario 2 | When the security guard left his post, I pocketed a rare coin.\n",
      "\n",
      "A) Not wrong, Wrong\n",
      "B) Wrong, Not wrong\n",
      "C) Wrong, Wrong\n",
      "D) Not wrong, Not wrong\n",
      "\n",
      "Example Answer: {\"answer\": \"A\"}\n",
      "\n",
      "Example Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | I bought an old pick-up truck for work. Scenario 2 | I looked up at the gorgeous waterfall and threw a rock at it.\n",
      "\n",
      "A) Wrong, Wrong\n",
      "B) Wrong, Not wrong\n",
      "C) Not wrong, Not wrong\n",
      "D) Not wrong, Wrong\n",
      "\n",
      "Example Answer: {\"answer\": \"C\"}\n",
      "\n",
      "Example Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | I really loved my newborn baby boy. Scenario 2 | The new girl is embarrassed to live in a trailer park, so I invite the class to her house.\n",
      "\n",
      "A) Wrong, Wrong\n",
      "B) Wrong, Not wrong\n",
      "C) Not wrong, Not wrong\n",
      "D) Not wrong, Wrong\n",
      "\n",
      "Example Answer: {\"answer\": \"D\"}\n",
      "\n",
      "Example Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | During the house's demolition, I pushed him into a wall. Scenario 2 | When I choose a babysitter for my twin nieces, I don't care about her racial background.\n",
      "\n",
      "A) Wrong, Wrong\n",
      "B) Wrong, Not wrong\n",
      "C) Not wrong, Wrong\n",
      "D) Not wrong, Not wrong\n",
      "\n",
      "Example Answer: {\"answer\": \"B\"}\n",
      "\n",
      "Given the examples above, your task is to answer the following question.\n",
      "\n",
      "Question: For which of these two scenarios does the main character (who uses I/me/my) do something clearly morally wrong, according to ordinary moral standards in the US as of 2020? Scenario 1 | After thinking long and hard, I used garden shears to fix my cat. Scenario 2 | I checked my teenager's bedroom closet because I thought he need help cleaning.\n",
      "\n",
      "A) Wrong, Wrong\n",
      "B) Not wrong, Wrong\n",
      "C) Wrong, Not wrong\n",
      "D) Not wrong, Not wrong\n",
      "\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "# Print example prompt\n",
    "print(lmb.datasets.mmlu.generate_prompt(examples, selected_questions.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c1ff00-a43e-41d1-9c89-6e6642f09620",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rows = []\n",
    "for i in range(3):\n",
    "    # Run benchmark\n",
    "    metrics = benchmark(\n",
    "        f\"epoch {i}\",\n",
    "        examples=examples,\n",
    "        questions=selected_questions,\n",
    "        generator=generator,\n",
    "        generator_options=llm_options,\n",
    "    )\n",
    "\n",
    "    rows.append(metrics)\n",
    "\n",
    "print_table(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c39e34-9333-4798-b059-b55748fbcade",
   "metadata": {},
   "source": [
    "## Estimate Positional Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af877f4d-2cc3-40b3-8a92-3ad28e5e0a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "uniform:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 131/160 [00:36<00:44,  1.54s/it]stamina.retry_scheduled\n",
      "uniform:  82%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                        | 132/160 [00:45<01:19,  2.82s/it]stamina.retry_scheduled\n",
      "uniform:  85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                     | 136/160 [01:13<01:53,  4.73s/it]stamina.retry_scheduled\n",
      "uniform:  86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                    | 137/160 [01:22<02:16,  5.92s/it]stamina.retry_scheduled\n",
      "uniform:  87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 139/160 [01:40<02:35,  7.43s/it]stamina.retry_scheduled\n",
      "uniform:  89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 142/160 [02:08<00:16,  1.11it/s]\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-BPEe54rqsvaF3sF22y4NJ5Pl on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:16\u001b[0m\n",
      "Cell \u001b[0;32mIn[7], line 35\u001b[0m, in \u001b[0;36mbenchmark\u001b[0;34m(description, examples, questions, generator, generator_options)\u001b[0m\n\u001b[1;32m     33\u001b[0m correct, errors \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm(as_completed(futures), total\u001b[38;5;241m=\u001b[39mn, desc\u001b[38;5;241m=\u001b[39mdescription):\n\u001b[0;32m---> 35\u001b[0m     evaluation \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m evaluation \u001b[38;5;129;01mis\u001b[39;00m Evaluation\u001b[38;5;241m.\u001b[39mCORRECT:\n\u001b[1;32m     37\u001b[0m         correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.6/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.6/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.6/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m, in \u001b[0;36mprocess_mcq\u001b[0;34m(generator, generator_options, mcq)\u001b[0m\n\u001b[1;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m lmb\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mmmlu\u001b[38;5;241m.\u001b[39mgenerate_prompt(examples, mcq)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Generate answer\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Evaluate response\u001b[39;00m\n\u001b[1;32m      9\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m lmb\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mmmlu\u001b[38;5;241m.\u001b[39mevaluate_response(mcq, response)\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/.venv/lib/python3.12/site-packages/stamina/_core.py:726\u001b[0m, in \u001b[0;36mretry.<locals>.retry_decorator.<locals>.sync_inner\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(wrapped)\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msync_inner\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:  \u001b[38;5;66;03m# type: ignore[return]\u001b[39;00m\n\u001b[0;32m--> 726\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mretry_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: RET503\u001b[39;49;00m\n\u001b[1;32m    727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/.venv/lib/python3.12/site-packages/stamina/_core.py:508\u001b[0m, in \u001b[0;36m_RetryContextIterator.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m Attempt(r, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRetrying\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbefore_sleep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_make_before_sleep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kw\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_maybe_test_mode_to_tenacity_kw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mAttempt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backoff_for_attempt_number\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/.venv/lib/python3.12/site-packages/tenacity/__init__.py:443\u001b[0m, in \u001b[0;36mBaseRetrying.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, args\u001b[38;5;241m=\u001b[39m(), kwargs\u001b[38;5;241m=\u001b[39m{})\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m AttemptManager(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/.venv/lib/python3.12/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/.venv/lib/python3.12/site-packages/tenacity/__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/.venv/lib/python3.12/site-packages/tenacity/__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.6/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.6/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/.venv/lib/python3.12/site-packages/stamina/_core.py:730\u001b[0m, in \u001b[0;36mretry.<locals>.retry_decorator.<locals>.sync_inner\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m retry_ctx\u001b[38;5;241m.\u001b[39mwith_name(  \u001b[38;5;66;03m# noqa: RET503\u001b[39;00m\n\u001b[1;32m    727\u001b[0m     name, args, kw\n\u001b[1;32m    728\u001b[0m ):\n\u001b[1;32m    729\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m attempt:\n\u001b[0;32m--> 730\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/src/llm_mcq_bias/models/_openai.py:56\u001b[0m, in \u001b[0;36mgpt_4o_mini\u001b[0;34m(prompt, options)\u001b[0m\n\u001b[1;32m     53\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Parse answer\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py:815\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    813\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    814\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 815\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/.venv/lib/python3.12/site-packages/openai/_base_client.py:1277\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1265\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1272\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1274\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1275\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1276\u001b[0m     )\n\u001b[0;32m-> 1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/.venv/lib/python3.12/site-packages/openai/_base_client.py:954\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 954\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/.venv/lib/python3.12/site-packages/openai/_base_client.py:1043\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1042\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/.venv/lib/python3.12/site-packages/openai/_base_client.py:1092\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/.venv/lib/python3.12/site-packages/openai/_base_client.py:1043\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m   1042\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/.venv/lib/python3.12/site-packages/openai/_base_client.py:1092\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/stickshift/llm-mcq-bias/.venv/lib/python3.12/site-packages/openai/_base_client.py:1058\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1057\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1061\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1062\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1067\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-BPEe54rqsvaF3sF22y4NJ5Pl on requests per day (RPD): Limit 10000, Used 10000, Requested 1. Please try again in 8.64s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n",
      "stamina.retry_scheduled\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Repeat over multiple iterations\n",
    "rows = []\n",
    "for _ in range(n_epochs):\n",
    "    # Sample questions\n",
    "    selected_questions = questions.sample(n=n_questions)\n",
    "\n",
    "    # Debias answer distribution\n",
    "    selected_questions = lmb.datasets.mmlu.normalize_question_answers(\n",
    "        selected_questions\n",
    "    )\n",
    "\n",
    "    # Initialize metrics\n",
    "    metrics = {}\n",
    "\n",
    "    # Record performance w/ original data\n",
    "    metrics[\"uniform\"] = benchmark(\n",
    "        \"uniform\",\n",
    "        examples=examples,\n",
    "        questions=selected_questions,\n",
    "        generator=generator,\n",
    "        generator_options=llm_options,\n",
    "    )\n",
    "\n",
    "    # Record performance w/ answers shifted to each position\n",
    "    for option in OPTIONS:\n",
    "        # Swap answers to selected option\n",
    "        q = lmb.datasets.mmlu.swap_options(selected_questions, option)\n",
    "\n",
    "        metrics[option] = benchmark(\n",
    "            option,\n",
    "            examples=examples,\n",
    "            questions=q,\n",
    "            generator=generator,\n",
    "            generator_options=llm_options,\n",
    "        )\n",
    "\n",
    "    rows.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b84788bf-d50f-4e45-9755-8ac2bc3ce45a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m keys \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrows\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys:\n\u001b[1;32m      4\u001b[0m     print_table([row[k] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows], title\u001b[38;5;241m=\u001b[39mk)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "keys = [k for k in rows[0]]\n",
    "\n",
    "for k in keys:\n",
    "    print_table([row[k] for row in rows], title=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf71dd-01e1-42e7-ab66-798960c4b2e4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "table = Table(\"uniform\", \"A\", \"B\", \"C\", \"D\", box=rich.box.SIMPLE)\n",
    "for row in rows:\n",
    "    baseline = row[\"uniform\"][\"accuracy\"]\n",
    "    offsets = {k: row[k][\"accuracy\"] - baseline for k in OPTIONS}\n",
    "    colors = {option: \"black\" for option in OPTIONS}\n",
    "    colors |= {option: \"red\" for option in OPTIONS if offsets[option] <= -0.05}\n",
    "    colors |= {option: \"green\" for option in OPTIONS if offsets[option] >= 0.05}\n",
    "    table.add_row(\n",
    "        f\"{baseline:0.2f}\",\n",
    "        f\"[{colors['A']}]{offsets['A']:0.2f}[/{colors['A']}]\",\n",
    "        f\"[{colors['B']}]{offsets['B']:0.2f}[/{colors['B']}]\",\n",
    "        f\"[{colors['C']}]{offsets['C']:0.2f}[/{colors['C']}]\",\n",
    "        f\"[{colors['D']}]{offsets['D']:0.2f}[/{colors['D']}]\",\n",
    "    )\n",
    "\n",
    "rich.print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940a7c2e-c8f3-465b-b68e-8f78f88e9171",
   "metadata": {},
   "source": [
    "# Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a8cfc-cc6e-410f-8bec-264b152f5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"results/demonstrate-bias-gpt-4o-mini-160-10epochs-run1.json\")\n",
    "path.write_text(json.dumps(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df4207d-7cf3-4eaf-9291-1fbfcc5729fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e3f48-eb24-4c3a-a4bd-38341b4f7dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
